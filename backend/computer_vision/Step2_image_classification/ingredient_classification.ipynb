{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1b2e654",
   "metadata": {},
   "source": [
    "\n",
    "For your ingredient detection project focusing on fruits and vegetables, using the \"Fruit and Vegetable Image Recognition Dataset\" along with a ResNet50 model from ImageNet for transfer learning is a solid approach. Below is an example code snippet in Python using TensorFlow and Keras to set up your model. This code assumes you have already downloaded your dataset and organized it into a directory structure suitable for TensorFlow's ImageDataGenerator.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "VERIFICAR LA VERSION COMPATIBLE TENSORFLOW CUDA CUDNN:\n",
    "https://www.tensorflow.org/install/source#gpu\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Made with <3\n",
    "# by Ivan Zepeda\n",
    "# github@ijzepeda-LC"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Setup Constants\n",
    "LEARNING_RATE=0.001\n",
    "EPOCHS=50\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T03:36:54.930157Z",
     "start_time": "2024-03-25T03:36:54.915070Z"
    }
   },
   "id": "cf20bd6d49f806e9",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24-03_23-36\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "# Get date\n",
    "dater= datetime.now()\n",
    "# format date in DDMMYY_HHMM\n",
    "DATE=dater.strftime(\"%d-%m_%H-%M\")\n",
    "print(DATE)\n",
    "\n",
    "# Get today date and format in month/day/year\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T03:36:54.945681Z",
     "start_time": "2024-03-25T03:36:54.932158Z"
    }
   },
   "id": "7f293ebd90272577",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4de9a865",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-25T03:37:05.018561Z",
     "start_time": "2024-03-25T03:36:54.947187Z"
    }
   },
   "outputs": [],
   "source": [
    "### Step 1: Import Necessary Libraries\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "436bb7cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-25T03:37:07.468668Z",
     "start_time": "2024-03-25T03:37:05.020562Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 34672 images belonging to 88 classes.\n",
      "Found 8620 images belonging to 88 classes.\n"
     ]
    }
   ],
   "source": [
    "### Step 2: Load and Preprocess the Dataset\n",
    "\n",
    "# Adjust the data_dir to the path where your dataset is stored. The ImageDataGenerator will apply some basic data augmentation to your dataset to improve training efficacy.\n",
    " \n",
    "data_dir = './FVIRD/train'  # Update this to the path of your dataset\n",
    "data_dir = './FOOD/train'  # Update this to the path of your dataset\n",
    "\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                                   rotation_range=20,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest',\n",
    "                                   validation_split=0.2)  # Using 20% of data for validation\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training')\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1eeca931",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-25T03:37:07.484771Z",
     "start_time": "2024-03-25T03:37:07.471250Z"
    }
   },
   "outputs": [],
   "source": [
    "### Step 3: Load the Pre-trained ResNet50 Model\n",
    "\n",
    "\n",
    "# base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba2cc4e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-25T03:37:09.635723Z",
     "start_time": "2024-03-25T03:37:07.486277Z"
    }
   },
   "outputs": [],
   "source": [
    "### Step 4: Add Custom Layers on Top of the Base Model\n",
    "\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "511d3acf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-25T03:37:09.651765Z",
     "start_time": "2024-03-25T03:37:09.637228Z"
    }
   },
   "outputs": [],
   "source": [
    "### Step 5: Freeze the Base Model Layers\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e8bb305",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-25T03:37:09.683004Z",
     "start_time": "2024-03-25T03:37:09.652767Z"
    }
   },
   "outputs": [],
   "source": [
    "### Step 6: Compile the Model\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=LEARNING_RATE), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please install GPU version of TF\n",
      "Tensroflow: 2.12.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "'\\nVersion\\tPython version\\tCompiler\\tBuild tools\\tcuDNN\\tCUDA \\ntensorflow-2.12.0\\t3.8-3.11\\tGCC 9.3.1\\tBazel 5.3.0\\t8.6\\t11.8\\n'"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### STEP pre-7: Verify if cuda\n",
    "import tensorflow as tf\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "if tf.test.gpu_device_name():\n",
    "    print(\"Default GPU Device: {}\".format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")\n",
    "print(\"Tensroflow:\",tf.__version__)\n",
    "\n",
    "\"\"\"\n",
    "Version\tPython version\tCompiler\tBuild tools\tcuDNN\tCUDA \n",
    "tensorflow-2.12.0\t3.8-3.11\tGCC 9.3.1\tBazel 5.3.0\t8.6\t11.8\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T03:37:09.698565Z",
     "start_time": "2024-03-25T03:37:09.685006Z"
    }
   },
   "id": "967fbcb4287d3b6b",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T03:37:09.713854Z",
     "start_time": "2024-03-25T03:37:09.699565Z"
    }
   },
   "id": "7be7276631e51892",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc14f95c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T05:01:19.066825Z",
     "start_time": "2024-03-25T03:37:09.715901Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1083/1083 [==============================] - 3204s 3s/step - loss: 2.0695 - accuracy: 0.4756 - val_loss: 1.2442 - val_accuracy: 0.6574\n",
      "Epoch 2/50\n",
      "1083/1083 [==============================] - 3214s 3s/step - loss: 1.4766 - accuracy: 0.5966 - val_loss: 1.1302 - val_accuracy: 0.6909\n",
      "Epoch 3/50\n",
      "1083/1083 [==============================] - 3373s 3s/step - loss: 1.3553 - accuracy: 0.6280 - val_loss: 1.0445 - val_accuracy: 0.7084\n",
      "Epoch 4/50\n",
      "1083/1083 [==============================] - 3283s 3s/step - loss: 1.2725 - accuracy: 0.6497 - val_loss: 1.0134 - val_accuracy: 0.7210\n",
      "Epoch 5/50\n",
      "1083/1083 [==============================] - 3177s 3s/step - loss: 1.1928 - accuracy: 0.6681 - val_loss: 0.9828 - val_accuracy: 0.7269\n",
      "Epoch 6/50\n",
      "1083/1083 [==============================] - 3145s 3s/step - loss: 1.1505 - accuracy: 0.6772 - val_loss: 1.0070 - val_accuracy: 0.7291\n",
      "Epoch 7/50\n",
      "1083/1083 [==============================] - 3142s 3s/step - loss: 1.1186 - accuracy: 0.6850 - val_loss: 0.9469 - val_accuracy: 0.7409\n",
      "Epoch 8/50\n",
      "1083/1083 [==============================] - 3133s 3s/step - loss: 1.0926 - accuracy: 0.6954 - val_loss: 0.9305 - val_accuracy: 0.7495\n",
      "Epoch 9/50\n",
      "1083/1083 [==============================] - 3191s 3s/step - loss: 1.0533 - accuracy: 0.7016 - val_loss: 0.9066 - val_accuracy: 0.7522\n",
      "Epoch 10/50\n",
      "1083/1083 [==============================] - 3193s 3s/step - loss: 1.0344 - accuracy: 0.7095 - val_loss: 0.9624 - val_accuracy: 0.7359\n",
      "Epoch 11/50\n",
      "1083/1083 [==============================] - 3147s 3s/step - loss: 1.0129 - accuracy: 0.7127 - val_loss: 0.8929 - val_accuracy: 0.7592\n",
      "Epoch 12/50\n",
      "1083/1083 [==============================] - 3157s 3s/step - loss: 0.9842 - accuracy: 0.7209 - val_loss: 0.8940 - val_accuracy: 0.7600\n",
      "Epoch 13/50\n",
      "1083/1083 [==============================] - 3146s 3s/step - loss: 0.9663 - accuracy: 0.7287 - val_loss: 0.9086 - val_accuracy: 0.7584\n",
      "Epoch 14/50\n",
      "1083/1083 [==============================] - 3136s 3s/step - loss: 0.9465 - accuracy: 0.7318 - val_loss: 0.8779 - val_accuracy: 0.7645\n",
      "Epoch 15/50\n",
      "1083/1083 [==============================] - 3141s 3s/step - loss: 0.9413 - accuracy: 0.7308 - val_loss: 0.8829 - val_accuracy: 0.7637\n",
      "Epoch 16/50\n",
      "1083/1083 [==============================] - 3135s 3s/step - loss: 0.9343 - accuracy: 0.7348 - val_loss: 0.8732 - val_accuracy: 0.7668\n",
      "Epoch 17/50\n",
      "1083/1083 [==============================] - 3140s 3s/step - loss: 0.9302 - accuracy: 0.7367 - val_loss: 0.8801 - val_accuracy: 0.7692\n",
      "Epoch 18/50\n",
      "1083/1083 [==============================] - 3135s 3s/step - loss: 0.9035 - accuracy: 0.7424 - val_loss: 0.8738 - val_accuracy: 0.7779\n",
      "Epoch 19/50\n",
      "1083/1083 [==============================] - 3135s 3s/step - loss: 0.8936 - accuracy: 0.7447 - val_loss: 0.8504 - val_accuracy: 0.7786\n",
      "Epoch 20/50\n",
      "1083/1083 [==============================] - 3096s 3s/step - loss: 0.8829 - accuracy: 0.7505 - val_loss: 0.8632 - val_accuracy: 0.7760\n",
      "Epoch 21/50\n",
      "1083/1083 [==============================] - 3179s 3s/step - loss: 0.8870 - accuracy: 0.7476 - val_loss: 0.9005 - val_accuracy: 0.7737\n",
      "Epoch 22/50\n",
      "1083/1083 [==============================] - 3156s 3s/step - loss: 0.8663 - accuracy: 0.7537 - val_loss: 0.9024 - val_accuracy: 0.7758\n",
      "Epoch 23/50\n",
      "1083/1083 [==============================] - 3153s 3s/step - loss: 0.8759 - accuracy: 0.7535 - val_loss: 0.8721 - val_accuracy: 0.7772\n",
      "Epoch 24/50\n",
      "1083/1083 [==============================] - 3142s 3s/step - loss: 0.8598 - accuracy: 0.7569 - val_loss: 0.8933 - val_accuracy: 0.7794\n",
      "Epoch 25/50\n",
      "1083/1083 [==============================] - 3075s 3s/step - loss: 0.8413 - accuracy: 0.7595 - val_loss: 0.9027 - val_accuracy: 0.7872\n",
      "Epoch 26/50\n",
      "1083/1083 [==============================] - 3072s 3s/step - loss: 0.8484 - accuracy: 0.7605 - val_loss: 0.9005 - val_accuracy: 0.7823\n",
      "Epoch 27/50\n",
      "1083/1083 [==============================] - 3068s 3s/step - loss: 0.8333 - accuracy: 0.7646 - val_loss: 0.9163 - val_accuracy: 0.7847\n",
      "Epoch 28/50\n",
      "1083/1083 [==============================] - 3073s 3s/step - loss: 0.8320 - accuracy: 0.7650 - val_loss: 0.8882 - val_accuracy: 0.7880\n",
      "Epoch 29/50\n",
      "1083/1083 [==============================] - 3107s 3s/step - loss: 0.8314 - accuracy: 0.7672 - val_loss: 0.9109 - val_accuracy: 0.7818\n",
      "Epoch 29: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x230000d0220>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Step 7: Train the Model\n",
    "DATE=dater.strftime(\"%d-%m_%H-%M\")\n",
    "\n",
    "# model.fit(\n",
    "#     train_generator,\n",
    "#     steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "#     validation_data=validation_generator,\n",
    "#     validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "#     epochs=EPOCHS)\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "\n",
    "# Path to save the model file\n",
    "checkpoint_filepath = \".\\\\models\\\\chkpt_model-0324--{epoch:02d}-{val_accuracy:.3f}.hdf5\"\n",
    "\n",
    "# Create a ModelCheckpoint callback\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_accuracy',  # Choose 'val_loss' or another metric\n",
    "    mode='max',  # For validation accuracy, higher is better so we use 'max'\n",
    "    save_best_only=True)\n",
    "\n",
    "# Create an EarlyStopping callback\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_loss',  # Monitor validation loss\n",
    "    mode='min',  # For validation loss, lower is better so we use 'min'\n",
    "    patience=5,  # Number of epochs with no improvement after which training will be stopped\n",
    "    verbose=1)\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[model_checkpoint_callback, early_stopping_callback])  # Add the callbacks here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f024ea",
   "metadata": {},
   "source": [
    "### Notes:\n",
    "\n",
    "- *Dataset and File Paths*: Ensure that your dataset directory structure is compatible with flow_from_directory. Typically, this means having a subdirectory for each class in both training and validation directories.\n",
    "- *Model Training*: The number of epochs, learning rate, and other hyperparameters are set to generic values. You might need to adjust these based on your specific dataset and training performance.\n",
    "- *Model Fine-Tuning*: After initial training with the base model layers frozen, you can choose to unfreeze some of the top layers of the base model and continue training to potentially improve accuracy. This involves setting layer.trainable = True for the layers you wish to fine-tune and recompiling the model.\n",
    "\n",
    "This code provides a starting point, but you'll likely need to tweak it based on your dataset's specifics and the performance you observe during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfc7aa31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T05:01:19.639954Z",
     "start_time": "2024-03-26T05:01:19.169850Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Saving the Model\n",
    "CURRENT_TRAINED_MODEL=f\"model_FOOD_{DATE}_LR{LEARNING_RATE}.h5\"\n",
    "model.save(CURRENT_TRAINED_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b47a1b18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T19:20:59.704445Z",
     "start_time": "2024-03-26T19:05:57.762719Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11738 images belonging to 88 classes.\n",
      "367/367 [==============================] - 901s 2s/step - loss: 0.8411 - accuracy: 0.8105\n",
      "Test Loss: 0.8410724997520447\n",
      "Test Accuracy: 0.810529887676239\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_data_dir='./FOOD/test'\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7b8f0c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T05:09:12.095795Z",
     "start_time": "2024-03-27T05:09:11.987770Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index to class mapping: {0: 'Artichoke', 1: 'Avocado', 2: 'Bacon', 3: 'Banana', 4: 'Beans', 5: 'Beetroot', 6: 'Bitter Gourd', 7: 'Bread', 8: 'Broccoli', 9: 'Butter', 10: 'Cabbage', 11: 'Cauliflower', 12: 'Cheese', 13: 'Chicken', 14: 'Chickpeas', 15: 'Cinnamon', 16: 'Corn', 17: 'Cucumber', 18: 'Garlic', 19: 'Ginger', 20: 'Gourd', 21: 'Ground Meat', 22: 'Ham', 23: 'Lentils', 24: 'Meat', 25: 'Milk', 26: 'Mushroom', 27: 'Onion', 28: 'Orange', 29: 'Paneer', 30: 'Papaya', 31: 'Radish', 32: 'Sweet Potato', 33: 'Tomato', 34: 'Turnip', 35: 'apple', 36: 'asparagus', 37: 'beef meat', 38: 'bell pepper', 39: 'black beans', 40: 'blueberries', 41: 'cambray', 42: 'cantaloupe', 43: 'carrots', 44: 'celery', 45: 'chayote', 46: 'cherries', 47: 'chilli pepper', 48: 'cilantro', 49: 'eggplant', 50: 'eggs', 51: 'fish', 52: 'grapefruit', 53: 'grapes', 54: 'green beans', 55: 'guava', 56: 'jalapeno', 57: 'juice bottle', 58: 'kimchi', 59: 'kiwi', 60: 'lemon', 61: 'lettuce', 62: 'lime', 63: 'mac&cheese', 64: 'mango', 65: 'okra', 66: 'paprika', 67: 'pasta', 68: 'peach', 69: 'pear', 70: 'peas', 71: 'pineapple', 72: 'plums', 73: 'pomegranate', 74: 'potatoes', 75: 'raspberries', 76: 'rice', 77: 'salmon', 78: 'soy beans', 79: 'spaggethi', 80: 'spinach', 81: 'strawberries', 82: 'tangerine', 83: 'train', 84: 'watermelon', 85: 'yam', 86: 'yogurth', 87: 'zuccini'}\n"
     ]
    }
   ],
   "source": [
    "# Retrieve class indices\n",
    "class_indices = train_generator.class_indices\n",
    "\n",
    "# Reverse the dictionary to map indices to class names\n",
    "index_to_class = {v: k for k, v in class_indices.items()}\n",
    "\n",
    "# Print the mapping of numerical labels to category names\n",
    "print(\"Index to class mapping:\", index_to_class)\n",
    "\n",
    " # save index_to_class to a txt file\n",
    "f = open(f\"{str(CURRENT_TRAINED_MODEL.split('.')[0])}_dic.txt\", \"w\")\n",
    "f.write(str(index_to_class))\n",
    "f.close()    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# f = open(f\"Categories_dict_mdl_{str(CURRENT_TRAINED_MODEL.split('.')[0])}.txt\", \"w\")\n",
    "# f.write(str(index_to_class))\n",
    "# f.close()    \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T19:20:59.736452Z",
     "start_time": "2024-03-26T19:20:59.724449Z"
    }
   },
   "id": "c4a6f51794a6e5fa",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./FOOD/test\\\\', './FOOD/test\\\\apple', './FOOD/test\\\\apple\\\\apple__008fc187.jpg', './FOOD/test\\\\apple\\\\apple__016de5e1.jpg', './FOOD/test\\\\apple\\\\apple__01eaa43b.jpg', './FOOD/test\\\\apple\\\\apple__01eaa43b.png', './FOOD/test\\\\apple\\\\apple__02bee309.jpg', './FOOD/test\\\\apple\\\\apple__03e68c28.jpg', './FOOD/test\\\\apple\\\\apple__03e68c28.png', './FOOD/test\\\\apple\\\\apple__053abd75.jpg']\n"
     ]
    },
    {
     "data": {
      "text/plain": "10733"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "path_test='./FOOD/test/**'\n",
    "testes=glob.glob(path_test, recursive=True)\n",
    "\n",
    "print(testes[:10])\n",
    "\n",
    "testes2 = [x for x in testes if x.endswith('jpg')]\n",
    "len(testes2)"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T19:21:00.437609Z",
     "start_time": "2024-03-26T19:20:59.738453Z"
    }
   },
   "id": "361bc6ec",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8903d751",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T19:29:47.397657Z",
     "start_time": "2024-03-26T19:29:30.023761Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 120ms/step\n",
      "Image: ./FOOD/test\\apple\\apple__008fc187.jpg\n",
      "✅CorrectPredicted class: 35 apple\n",
      "Correct:1. Incorrect:0\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "Image: ./FOOD/test\\apple\\apple__47b7877f.jpg\n",
      "✅CorrectPredicted class: 35 apple\n",
      "Correct:2. Incorrect:0\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Image: ./FOOD/test\\apple\\apple__a82cb851.jpg\n",
      "✅CorrectPredicted class: 35 apple\n",
      "Correct:3. Incorrect:0\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "Image: ./FOOD/test\\Artichoke\\Artichoke__06d7c6a2.jpg\n",
      "✅CorrectPredicted class: 0 Artichoke\n",
      "Correct:4. Incorrect:0\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "Image: ./FOOD/test\\Artichoke\\Artichoke__811ca008.jpg\n",
      "✅CorrectPredicted class: 0 Artichoke\n",
      "Correct:5. Incorrect:0\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Image: ./FOOD/test\\asparagus\\asparagus__06f5d2c6.jpg\n",
      "✅CorrectPredicted class: 36 asparagus\n",
      "Correct:6. Incorrect:0\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Image: ./FOOD/test\\asparagus\\asparagus__516a314b.jpg\n",
      "✅CorrectPredicted class: 36 asparagus\n",
      "Correct:7. Incorrect:0\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Image: ./FOOD/test\\asparagus\\asparagus__9fac27c5.jpg\n",
      "✅CorrectPredicted class: 36 asparagus\n",
      "Correct:8. Incorrect:0\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Image: ./FOOD/test\\asparagus\\asparagus__e7010949.jpg\n",
      "✅CorrectPredicted class: 36 asparagus\n",
      "Correct:9. Incorrect:0\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Image: ./FOOD/test\\Avocado\\Avocado__7bfc75a6.jpg\n",
      "✅CorrectPredicted class: 1 Avocado\n",
      "Correct:10. Incorrect:0\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Image: ./FOOD/test\\Bacon\\Bacon__0339a005.jpg\n",
      "✅CorrectPredicted class: 2 Bacon\n",
      "Correct:11. Incorrect:0\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Image: ./FOOD/test\\Bacon\\Bacon__5543b342.jpg\n",
      "✅CorrectPredicted class: 2 Bacon\n",
      "Correct:12. Incorrect:0\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Image: ./FOOD/test\\Bacon\\Bacon__b3b656ca.jpg\n",
      "✅CorrectPredicted class: 2 Bacon\n",
      "Correct:13. Incorrect:0\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "Image: ./FOOD/test\\Banana\\Banana__1945dff6.jpg\n",
      "✅CorrectPredicted class: 3 Banana\n",
      "Correct:14. Incorrect:0\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Image: ./FOOD/test\\Beans\\Beans__11c62ded.jpg\n",
      "✅CorrectPredicted class: 4 Beans\n",
      "Correct:15. Incorrect:0\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Image: ./FOOD/test\\Beans\\Beans__6945c9e2.jpg\n",
      "✅CorrectPredicted class: 4 Beans\n",
      "Correct:16. Incorrect:0\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Image: ./FOOD/test\\Beans\\Beans__b152ebaf.jpg\n",
      "✅CorrectPredicted class: 4 Beans\n",
      "Correct:17. Incorrect:0\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Image: ./FOOD/test\\beef meat\\beef meat__132baf48.jpg\n",
      "❌IncorrectPredicted class: 24 Meat\n",
      "Correct:17. Incorrect:1\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Image: ./FOOD/test\\beef meat\\beef meat__b04e6af8.jpg\n",
      "❌IncorrectPredicted class: 24 Meat\n",
      "Correct:17. Incorrect:2\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Image: ./FOOD/test\\Beetroot\\Beetroot__29f1d087.jpg\n",
      "✅CorrectPredicted class: 5 Beetroot\n",
      "Correct:18. Incorrect:2\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Image: ./FOOD/test\\Beetroot\\Beetroot__83827c26.jpg\n",
      "✅CorrectPredicted class: 5 Beetroot\n",
      "Correct:19. Incorrect:2\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Image: ./FOOD/test\\Beetroot\\Beetroot__e577b680.jpg\n",
      "✅CorrectPredicted class: 5 Beetroot\n",
      "Correct:20. Incorrect:2\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Image: ./FOOD/test\\bell pepper\\bell pepper__6eddbca9.jpg\n",
      "✅CorrectPredicted class: 38 bell pepper\n",
      "Correct:21. Incorrect:2\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Image: ./FOOD/test\\Bitter Gourd\\Bitter Gourd__16d78054.jpg\n",
      "✅CorrectPredicted class: 6 Bitter Gourd\n",
      "Correct:22. Incorrect:2\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Image: ./FOOD/test\\black beans\\black beans__aac3b147.jpg\n",
      "❌IncorrectPredicted class: 67 pasta\n",
      "Correct:22. Incorrect:3\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Image: ./FOOD/test\\blueberries\\blueberries__7179bc57.jpg\n",
      "✅CorrectPredicted class: 40 blueberries\n",
      "Correct:23. Incorrect:3\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Image: ./FOOD/test\\Broccoli\\Broccoli__127bbcdd.jpg\n",
      "✅CorrectPredicted class: 8 Broccoli\n",
      "Correct:24. Incorrect:3\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Image: ./FOOD/test\\Broccoli\\Broccoli__bdec6881.jpg\n",
      "✅CorrectPredicted class: 8 Broccoli\n",
      "Correct:25. Incorrect:3\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Image: ./FOOD/test\\Butter\\Butter__85b23d33.jpg\n",
      "✅CorrectPredicted class: 9 Butter\n",
      "Correct:26. Incorrect:3\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Image: ./FOOD/test\\Cabbage\\Cabbage__31fe5747.jpg\n",
      "✅CorrectPredicted class: 10 Cabbage\n",
      "Correct:27. Incorrect:3\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "Image: ./FOOD/test\\Cabbage\\Cabbage__c163856d.jpg\n",
      "✅CorrectPredicted class: 10 Cabbage\n",
      "Correct:28. Incorrect:3\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "Image: ./FOOD/test\\cambray\\cambray__91611d18.jpg\n",
      "✅CorrectPredicted class: 41 cambray\n",
      "Correct:29. Incorrect:3\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Image: ./FOOD/test\\cantaloupe\\cantaloupe__6979fce2.jpg\n",
      "✅CorrectPredicted class: 42 cantaloupe\n",
      "Correct:30. Incorrect:3\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Image: ./FOOD/test\\carrots\\carrots__d0f974eb.jpg\n",
      "✅CorrectPredicted class: 43 carrots\n",
      "Correct:31. Incorrect:3\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Image: ./FOOD/test\\Cauliflower\\Cauliflower__c8b39a81.jpg\n",
      "✅CorrectPredicted class: 11 Cauliflower\n",
      "Correct:32. Incorrect:3\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Image: ./FOOD/test\\celery\\celery__fc559f6b.jpg\n",
      "✅CorrectPredicted class: 44 celery\n",
      "Correct:33. Incorrect:3\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Image: ./FOOD/test\\Cheese\\Cheese__25fa49f6.jpg\n",
      "✅CorrectPredicted class: 12 Cheese\n",
      "Correct:34. Incorrect:3\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "Image: ./FOOD/test\\Cheese\\Cheese__c50a55b3.jpg\n",
      "✅CorrectPredicted class: 12 Cheese\n",
      "Correct:35. Incorrect:3\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "Image: ./FOOD/test\\cherries\\cherries__880df898.jpg\n",
      "✅CorrectPredicted class: 46 cherries\n",
      "Correct:36. Incorrect:3\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "Image: ./FOOD/test\\Chicken\\Chicken__7db6338f.jpg\n",
      "✅CorrectPredicted class: 13 Chicken\n",
      "Correct:37. Incorrect:3\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "Image: ./FOOD/test\\Chickpeas\\Chickpeas__799d8810.jpg\n",
      "✅CorrectPredicted class: 14 Chickpeas\n",
      "Correct:38. Incorrect:3\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Image: ./FOOD/test\\chilli pepper\\chilli pepper__293572ad.jpg\n",
      "❌IncorrectPredicted class: 56 jalapeno\n",
      "Correct:38. Incorrect:4\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "Image: ./FOOD/test\\cilantro\\cilantro__99c55727.jpg\n",
      "✅CorrectPredicted class: 48 cilantro\n",
      "Correct:39. Incorrect:4\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Image: ./FOOD/test\\Cucumber\\Cucumber__02840af0.jpg\n",
      "✅CorrectPredicted class: 17 Cucumber\n",
      "Correct:40. Incorrect:4\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "Image: ./FOOD/test\\Cucumber\\Cucumber__a9a2cfe9.jpg\n",
      "✅CorrectPredicted class: 17 Cucumber\n",
      "Correct:41. Incorrect:4\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Image: ./FOOD/test\\eggplant\\eggplant__532e6a65.jpg\n",
      "✅CorrectPredicted class: 49 eggplant\n",
      "Correct:42. Incorrect:4\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Image: ./FOOD/test\\eggplant\\eggplant__dda1bd18.jpg\n",
      "✅CorrectPredicted class: 49 eggplant\n",
      "Correct:43. Incorrect:4\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Image: ./FOOD/test\\eggs\\eggs__88c8cecd.jpg\n",
      "✅CorrectPredicted class: 50 eggs\n",
      "Correct:44. Incorrect:4\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Image: ./FOOD/test\\fish\\fish__4952c339.jpg\n",
      "✅CorrectPredicted class: 51 fish\n",
      "Correct:45. Incorrect:4\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "Image: ./FOOD/test\\Garlic\\Garlic__321a39f6.jpg\n",
      "✅CorrectPredicted class: 18 Garlic\n",
      "Correct:46. Incorrect:4\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Image: ./FOOD/test\\Ginger\\Ginger__a966f897.jpg\n",
      "✅CorrectPredicted class: 19 Ginger\n",
      "Correct:47. Incorrect:4\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "Image: ./FOOD/test\\Gourd\\Gourd__7f769089.jpg\n",
      "✅CorrectPredicted class: 20 Gourd\n",
      "Correct:48. Incorrect:4\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "Image: ./FOOD/test\\grapefruit\\grapefruit__524b6c2b.jpg\n",
      "✅CorrectPredicted class: 52 grapefruit\n",
      "Correct:49. Incorrect:4\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Image: ./FOOD/test\\grapes\\grapes__127327ba.jpg\n",
      "✅CorrectPredicted class: 53 grapes\n",
      "Correct:50. Incorrect:4\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Image: ./FOOD/test\\grapes\\grapes__c3580d72.jpg\n",
      "✅CorrectPredicted class: 53 grapes\n",
      "Correct:51. Incorrect:4\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Image: ./FOOD/test\\green beans\\green beans__61b82b36.jpg\n",
      "✅CorrectPredicted class: 54 green beans\n",
      "Correct:52. Incorrect:4\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Image: ./FOOD/test\\Ground Meat\\Ground Meat__09b97ed9.jpg\n",
      "✅CorrectPredicted class: 21 Ground Meat\n",
      "Correct:53. Incorrect:4\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Image: ./FOOD/test\\Ground Meat\\Ground Meat__b09c86e5.jpg\n",
      "✅CorrectPredicted class: 21 Ground Meat\n",
      "Correct:54. Incorrect:4\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "Image: ./FOOD/test\\guava\\guava__747102f8.jpg\n",
      "✅CorrectPredicted class: 55 guava\n",
      "Correct:55. Incorrect:4\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "Image: ./FOOD/test\\Ham\\Ham__1b3cd3b4.jpg\n",
      "✅CorrectPredicted class: 22 Ham\n",
      "Correct:56. Incorrect:4\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Image: ./FOOD/test\\Ham\\Ham__aeea3996.jpg\n",
      "❌IncorrectPredicted class: 0 Artichoke\n",
      "Correct:56. Incorrect:5\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "Image: ./FOOD/test\\jalapeno\\jalapeno__99b5d1c0.jpg\n",
      "✅CorrectPredicted class: 56 jalapeno\n",
      "Correct:57. Incorrect:5\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Image: ./FOOD/test\\juice bottle\\juice bottle__64a7acc0.jpg\n",
      "✅CorrectPredicted class: 57 juice bottle\n",
      "Correct:58. Incorrect:5\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "Image: ./FOOD/test\\kimchi\\kimchi__24c7bf3d.jpg\n",
      "✅CorrectPredicted class: 58 kimchi\n",
      "Correct:59. Incorrect:5\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Image: ./FOOD/test\\kiwi\\kiwi__41eed431.jpg\n",
      "✅CorrectPredicted class: 59 kiwi\n",
      "Correct:60. Incorrect:5\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "Image: ./FOOD/test\\kiwi\\kiwi__e3009a9a.jpg\n",
      "✅CorrectPredicted class: 59 kiwi\n",
      "Correct:61. Incorrect:5\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Image: ./FOOD/test\\lemon\\lemon__a990a33b.jpg\n",
      "❌IncorrectPredicted class: 79 spaggethi\n",
      "Correct:61. Incorrect:6\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Image: ./FOOD/test\\Lentils\\Lentils__364f1b42.jpg\n",
      "❌IncorrectPredicted class: 4 Beans\n",
      "Correct:61. Incorrect:7\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Image: ./FOOD/test\\Lentils\\Lentils__aae465d5.jpg\n",
      "✅CorrectPredicted class: 23 Lentils\n",
      "Correct:62. Incorrect:7\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Image: ./FOOD/test\\lettuce\\lettuce__2c8fa1ed.jpg\n",
      "✅CorrectPredicted class: 61 lettuce\n",
      "Correct:63. Incorrect:7\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Image: ./FOOD/test\\lettuce\\lettuce__be6b77f0.jpg\n",
      "✅CorrectPredicted class: 61 lettuce\n",
      "Correct:64. Incorrect:7\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Image: ./FOOD/test\\lime\\lime__b380501c.jpg\n",
      "✅CorrectPredicted class: 62 lime\n",
      "Correct:65. Incorrect:7\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "Image: ./FOOD/test\\mac&cheese\\mac&cheese__8b37cf64.jpg\n",
      "✅CorrectPredicted class: 63 mac&cheese\n",
      "Correct:66. Incorrect:7\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Image: ./FOOD/test\\mango\\mango__6fefe961.jpg\n",
      "✅CorrectPredicted class: 64 mango\n",
      "Correct:67. Incorrect:7\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Image: ./FOOD/test\\Meat\\Meat__76dee7cd.jpg\n",
      "❌IncorrectPredicted class: 37 beef meat\n",
      "Correct:67. Incorrect:8\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Image: ./FOOD/test\\Milk\\Milk__4cb7b51c.jpg\n",
      "✅CorrectPredicted class: 25 Milk\n",
      "Correct:68. Incorrect:8\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Image: ./FOOD/test\\Milk\\Milk__e5d0fcb5.jpg\n",
      "✅CorrectPredicted class: 25 Milk\n",
      "Correct:69. Incorrect:8\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Image: ./FOOD/test\\Mushroom\\Mushroom__c4f7ac06.jpg\n",
      "✅CorrectPredicted class: 26 Mushroom\n",
      "Correct:70. Incorrect:8\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Image: ./FOOD/test\\okra\\okra__c0b16c38.jpg\n",
      "❌IncorrectPredicted class: 74 potatoes\n",
      "Correct:70. Incorrect:9\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Image: ./FOOD/test\\Onion\\Onion__bc388b91.jpg\n",
      "❌IncorrectPredicted class: 12 Cheese\n",
      "Correct:70. Incorrect:10\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Image: ./FOOD/test\\Paneer\\Paneer__1394ded1.jpg\n",
      "✅CorrectPredicted class: 29 Paneer\n",
      "Correct:71. Incorrect:10\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Image: ./FOOD/test\\Papaya\\Papaya__a528cc92.jpg\n",
      "✅CorrectPredicted class: 30 Papaya\n",
      "Correct:72. Incorrect:10\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Image: ./FOOD/test\\paprika\\paprika__99a5615e.jpg\n",
      "✅CorrectPredicted class: 66 paprika\n",
      "Correct:73. Incorrect:10\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Image: ./FOOD/test\\pasta\\pasta__3f113677.jpg\n",
      "✅CorrectPredicted class: 67 pasta\n",
      "Correct:74. Incorrect:10\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Image: ./FOOD/test\\peach\\peach__08246a32.jpg\n",
      "✅CorrectPredicted class: 68 peach\n",
      "Correct:75. Incorrect:10\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Image: ./FOOD/test\\peach\\peach__dbddacbc.jpg\n",
      "✅CorrectPredicted class: 68 peach\n",
      "Correct:76. Incorrect:10\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Image: ./FOOD/test\\pear\\pear__9cbf74fc.jpg\n",
      "✅CorrectPredicted class: 69 pear\n",
      "Correct:77. Incorrect:10\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "Image: ./FOOD/test\\peas\\peas__56de2d6a.jpg\n",
      "✅CorrectPredicted class: 70 peas\n",
      "Correct:78. Incorrect:10\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "Image: ./FOOD/test\\pineapple\\pineapple__04e6bdcb.jpg\n",
      "✅CorrectPredicted class: 71 pineapple\n",
      "Correct:79. Incorrect:10\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Image: ./FOOD/test\\pineapple\\pineapple__b3f3ee15.jpg\n",
      "✅CorrectPredicted class: 71 pineapple\n",
      "Correct:80. Incorrect:10\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Image: ./FOOD/test\\plums\\plums__560a724f.jpg\n",
      "✅CorrectPredicted class: 72 plums\n",
      "Correct:81. Incorrect:10\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Image: ./FOOD/test\\pomegranate\\pomegranate__1d3238ac.jpg\n",
      "✅CorrectPredicted class: 73 pomegranate\n",
      "Correct:82. Incorrect:10\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "Image: ./FOOD/test\\pomegranate\\pomegranate__d636f401.jpg\n",
      "✅CorrectPredicted class: 73 pomegranate\n",
      "Correct:83. Incorrect:10\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "Image: ./FOOD/test\\potatoes\\potatoes__bb78bcde.jpg\n",
      "❌IncorrectPredicted class: 12 Cheese\n",
      "Correct:83. Incorrect:11\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Image: ./FOOD/test\\raspberries\\raspberries__5ecea54c.jpg\n",
      "✅CorrectPredicted class: 75 raspberries\n",
      "Correct:84. Incorrect:11\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Image: ./FOOD/test\\rice\\rice__351959fe.jpg\n",
      "✅CorrectPredicted class: 76 rice\n",
      "Correct:85. Incorrect:11\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Image: ./FOOD/test\\salmon\\salmon__13c08aa6.jpg\n",
      "✅CorrectPredicted class: 77 salmon\n",
      "Correct:86. Incorrect:11\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Image: ./FOOD/test\\salmon\\salmon__c17e3632.jpg\n",
      "❌IncorrectPredicted class: 51 fish\n",
      "Correct:86. Incorrect:12\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Image: ./FOOD/test\\spaggethi\\spaggethi__3cdbd6b5.jpg\n",
      "✅CorrectPredicted class: 79 spaggethi\n",
      "Correct:87. Incorrect:12\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "Image: ./FOOD/test\\spinach\\spinach__08817c3d.jpg\n",
      "❌IncorrectPredicted class: 61 lettuce\n",
      "Correct:87. Incorrect:13\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Image: ./FOOD/test\\strawberries\\strawberries__5b06ca92.jpg\n",
      "✅CorrectPredicted class: 81 strawberries\n",
      "Correct:88. Incorrect:13\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Image: ./FOOD/test\\Sweet Potato\\Sweet Potato__37999a1d.jpg\n",
      "✅CorrectPredicted class: 32 Sweet Potato\n",
      "Correct:89. Incorrect:13\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Image: ./FOOD/test\\tangerine\\tangerine__815bef8e.jpg\n",
      "❌IncorrectPredicted class: 68 peach\n",
      "Correct:89. Incorrect:14\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Image: ./FOOD/test\\Tomato\\Tomato__f5470040.jpg\n",
      "✅CorrectPredicted class: 33 Tomato\n",
      "Correct:90. Incorrect:14\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Image: ./FOOD/test\\watermelon\\watermelon__81eca825.jpg\n",
      "✅CorrectPredicted class: 84 watermelon\n",
      "Correct:91. Incorrect:14\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Image: ./FOOD/test\\yam\\yam__59bf3972.jpg\n",
      "✅CorrectPredicted class: 85 yam\n",
      "Correct:92. Incorrect:14\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "Image: ./FOOD/test\\yogurth\\yogurth__90a5978f.jpg\n",
      "✅CorrectPredicted class: 86 yogurth\n",
      "Correct:93. Incorrect:14\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Image: ./FOOD/test\\zuccini\\zuccini__9ee84131.jpg\n",
      "✅CorrectPredicted class: 87 zuccini\n",
      "Correct:94. Incorrect:14\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Load and preprocess individual images\n",
    "def preprocess_image(image_path):\n",
    "    img = image.load_img(image_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = preprocess_input(img_array)\n",
    "    return img_array\n",
    "\n",
    "# Paths to your test images\n",
    "image_paths = testes2[::100]#['path/to/image1.jpg', 'path/to/image2.jpg', ...]\n",
    "\n",
    "# Make predictions for each image\n",
    "correct=0\n",
    "incorrect=0\n",
    "for image_path in image_paths:\n",
    "    preprocessed_image = preprocess_image(image_path)\n",
    "    prediction = model.predict(preprocessed_image)\n",
    "    predicted_class = np.argmax(prediction)\n",
    "    classe=str(image_path.split('\\\\')[-2])\n",
    "    print(\"Image:\", image_path)\n",
    "    if(classe.lower()==index_to_class[predicted_class].lower()):\n",
    "        print(\"✅Correct\", end=\"\")\n",
    "        correct=correct+1\n",
    "    else:\n",
    "        print(\"❌Incorrect\", end=\"\")\n",
    "        incorrect=incorrect+1\n",
    "    print(\"Predicted class:\", predicted_class, index_to_class[predicted_class])\n",
    "        \n",
    "#     print(\"Prediction probabilities:\", prediction)\n",
    "    print(f\"Correct:{correct}. Incorrect:{incorrect}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a12d888d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T19:26:53.178174Z",
     "start_time": "2024-03-26T19:26:53.165171Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 87 zuccini\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted class:\", predicted_class, index_to_class[predicted_class])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc4363f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T19:26:53.195177Z",
     "start_time": "2024-03-26T19:26:53.180175Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "488a91c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T19:26:53.209181Z",
     "start_time": "2024-03-26T19:26:53.199179Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35d3fba1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T19:27:02.143184Z",
     "start_time": "2024-03-26T19:26:53.211182Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 287ms/step\n",
      "Image: C:\\Users\\ijzep\\Downloads\\OwnDataset\\apples.jpeg\n",
      "Predicted class: 35 apple\n",
      "1/1 [==============================] - 0s 377ms/step\n",
      "Image: C:\\Users\\ijzep\\Downloads\\OwnDataset\\banans.jpeg\n",
      "Predicted class: 3 Banana\n",
      "1/1 [==============================] - 0s 229ms/step\n",
      "Image: C:\\Users\\ijzep\\Downloads\\OwnDataset\\banans2.jpeg\n",
      "Predicted class: 3 Banana\n",
      "1/1 [==============================] - 0s 295ms/step\n",
      "Image: C:\\Users\\ijzep\\Downloads\\OwnDataset\\brocoli.jpeg\n",
      "Predicted class: 8 Broccoli\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "Image: C:\\Users\\ijzep\\Downloads\\OwnDataset\\cantaloupe.jpeg\n",
      "Predicted class: 42 cantaloupe\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "Image: C:\\Users\\ijzep\\Downloads\\OwnDataset\\carrots.jpeg\n",
      "Predicted class: 43 carrots\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "Image: C:\\Users\\ijzep\\Downloads\\OwnDataset\\carrots2.jpeg\n",
      "Predicted class: 43 carrots\n",
      "1/1 [==============================] - 0s 449ms/step\n",
      "Image: C:\\Users\\ijzep\\Downloads\\OwnDataset\\cucumber.jpeg\n",
      "Predicted class: 17 Cucumber\n",
      "1/1 [==============================] - 0s 318ms/step\n",
      "Image: C:\\Users\\ijzep\\Downloads\\OwnDataset\\garlics.jpeg\n",
      "Predicted class: 18 Garlic\n",
      "1/1 [==============================] - 1s 626ms/step\n",
      "Image: C:\\Users\\ijzep\\Downloads\\OwnDataset\\mushrooms.jpeg\n",
      "Predicted class: 26 Mushroom\n",
      "1/1 [==============================] - 0s 312ms/step\n",
      "Image: C:\\Users\\ijzep\\Downloads\\OwnDataset\\onion (2).jpeg\n",
      "Predicted class: 27 Onion\n",
      "1/1 [==============================] - 0s 384ms/step\n",
      "Image: C:\\Users\\ijzep\\Downloads\\OwnDataset\\onion.jpeg\n",
      "Predicted class: 27 Onion\n",
      "1/1 [==============================] - 0s 374ms/step\n",
      "Image: C:\\Users\\ijzep\\Downloads\\OwnDataset\\onions (2).jpeg\n",
      "Predicted class: 27 Onion\n",
      "\n",
      "1/1 [==============================] - 0s 367ms/step\n",
      "Image: C:\\Users\\ijzep\\Downloads\\OwnDataset\\onions.jpeg\n",
      "Predicted class: 27 Onion\n",
      "\n",
      "1/1 [==============================] - 0s 354ms/step\n",
      "Image: C:\\Users\\ijzep\\Downloads\\OwnDataset\\pepper.jpeg\n",
      "Predicted class: 38 bell pepper\n",
      "\n",
      "1/1 [==============================] - 0s 182ms/step\n",
      "Image: C:\\Users\\ijzep\\Downloads\\OwnDataset\\spinach.jpeg\n",
      "Predicted class: 80 spinach\n",
      "\n",
      "1/1 [==============================] - 0s 217ms/step\n",
      "Image: C:\\Users\\ijzep\\Downloads\\OwnDataset\\sweetpotato.jpeg\n",
      "Predicted class: 32 Sweet Potato\n",
      "1/1 [==============================] - 0s 246ms/step\n",
      "Image: C:\\Users\\ijzep\\Downloads\\OwnDataset\\tangerine.jpeg\n",
      "Predicted class: 82 tangerine\n",
      "1/1 [==============================] - 0s 184ms/step\n",
      "Image: C:\\Users\\ijzep\\Downloads\\OwnDataset\\tomato.jpeg\n",
      "Predicted class: 33 Tomato\n",
      "1/1 [==============================] - 0s 197ms/step\n",
      "Image: C:\\Users\\ijzep\\Downloads\\OwnDataset\\yam.jpeg\n",
      "Predicted class: 85 yam\n"
     ]
    }
   ],
   "source": [
    "path_ownds='C:\\\\Users\\\\ijzep\\Downloads\\\\OwnDataset\\\\*'\n",
    "ownds=glob.glob(path_ownds)\n",
    "\n",
    "# Make predictions for each image\n",
    "for image_path in ownds:\n",
    "    preprocessed_image = preprocess_image(image_path)\n",
    "    prediction = model.predict(preprocessed_image)\n",
    "    predicted_class = np.argmax(prediction)\n",
    "    print(\"Image:\", image_path)\n",
    "    print(\"Predicted class:\", predicted_class, index_to_class[predicted_class])\n",
    "#     print(\"Prediction probabilities:\", prediction)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "298376d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T19:27:02.159188Z",
     "start_time": "2024-03-26T19:27:02.149185Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Artichoke', 'Avocado', 'Bacon', 'Banana', 'Beans', 'Beetroot', 'Bitter Gourd', 'Bread', 'Broccoli', 'Butter', 'Cabbage', 'Cauliflower', 'Cheese', 'Chicken', 'Chickpeas', 'Cinnamon', 'Corn', 'Cucumber', 'Garlic', 'Ginger', 'Gourd', 'Ground Meat', 'Ham', 'Lentils', 'Meat', 'Milk', 'Mushroom', 'Onion', 'Orange', 'Paneer', 'Papaya', 'Radish', 'Sweet Potato', 'Tomato', 'Turnip', 'apple', 'asparagus', 'beef meat', 'bell pepper', 'black beans', 'blueberries', 'cambray', 'cantaloupe', 'carrots', 'celery', 'chayote', 'cherries', 'chilli pepper', 'cilantro', 'eggplant', 'eggs', 'fish', 'grapefruit', 'grapes', 'green beans', 'guava', 'jalapeno', 'juice bottle', 'kimchi', 'kiwi', 'lemon', 'lettuce', 'lime', 'mac&cheese', 'mango', 'okra', 'paprika', 'pasta', 'peach', 'pear', 'peas', 'pineapple', 'plums', 'pomegranate', 'potatoes', 'raspberries', 'rice', 'salmon', 'soy beans', 'spaggethi', 'spinach', 'strawberries', 'tangerine', 'train', 'watermelon', 'yam', 'yogurth', 'zuccini']\n"
     ]
    }
   ],
   "source": [
    "print(list(index_to_class.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a3c0108",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T19:27:02.175192Z",
     "start_time": "2024-03-26T19:27:02.163189Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(f'Categories_list_mdl_{CURRENT_TRAINED_MODEL}.txt', 'w') as file:\n",
    "    file.write(str(list(index_to_class.values())))"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T19:27:02.190195Z",
     "start_time": "2024-03-26T19:27:02.177193Z"
    }
   },
   "id": "ed36ec4dbdeb5faf",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "eb57fe127e9557ca"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# AGREGAR METRICAS CON LO YA ENTRENADO\n",
    "## AUNQUE HAYA SALIDO ERROR"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9acf46814e99ecfe"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367/367 [==============================] - 905s 2s/step\n"
     ]
    }
   ],
   "source": [
    "# Asumiendo que 'model' es tu modelo entrenado y 'test_generator' es tu generador de datos de prueba.\n",
    "predictions = model.predict(test_generator)\n",
    "y_pred = np.argmax(predictions, axis=1)  # Convierte las probabilidades a etiquetas de clase si es necesario\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T19:57:44.702231Z",
     "start_time": "2024-03-26T19:42:38.456597Z"
    }
   },
   "id": "77c41b6d79aadd4c",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Obtain tru labels\n",
    "y_true = test_generator.classes\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T19:57:44.718236Z",
     "start_time": "2024-03-26T19:57:44.704233Z"
    }
   },
   "id": "5040f0ecc77c94a",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.013204975293917192\n",
      "Precision by class: [0.01680672 0.02298851 0.03436426 0.00775194 0.0033557  0.03833866\n",
      " 0.         0.06666667 0.02162162 0.00746269 0.01570681 0.01438849\n",
      " 0.00404858 0.         0.01587302 0.         0.         0.01226994\n",
      " 0.         0.01       0.00666667 0.00740741 0.01612903 0.00819672\n",
      " 0.00813008 0.         0.02884615 0.00787402 0.         0.\n",
      " 0.01234568 0.         0.         0.         0.         0.03313253\n",
      " 0.0265252  0.01117318 0.01388889 0.         0.         0.03370787\n",
      " 0.         0.         0.01851852 0.01428571 0.02272727 0.\n",
      " 0.01470588 0.02512563 0.01621622 0.0173913  0.03546099 0.00645161\n",
      " 0.01041667 0.02339181 0.01587302 0.00564972 0.03389831 0.01851852\n",
      " 0.         0.02222222 0.01388889 0.         0.         0.03191489\n",
      " 0.         0.01273885 0.02083333 0.01183432 0.0075188  0.02222222\n",
      " 0.         0.         0.         0.00694444 0.02912621 0.\n",
      " 0.         0.         0.         0.         0.01470588 0.\n",
      " 0.00724638 0.         0.01       0.        ]\n",
      "Recall: 0.010631637480325674\n",
      "F1-Score: 0.01083880736297395\n",
      "Confusion Matrix:\n",
      "[[ 4  2  8 ...  1  1  2]\n",
      " [ 5  4  6 ...  1  1  1]\n",
      " [ 5  7 10 ...  2  0  4]\n",
      " ...\n",
      " [ 2  2  2 ...  0  1  0]\n",
      " [ 2  2  3 ...  0  1  0]\n",
      " [ 3  1  2 ...  1  1  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ijzep\\.conda\\envs\\recipix\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Precisión\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# Precisión por clase\n",
    "precision = precision_score(y_true, y_pred, average=None)\n",
    "print(f'Precision by class: {precision}')\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_true, y_pred, average='macro')\n",
    "print(f'Recall: {recall}')\n",
    "\n",
    "# F1-Score\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "print(f'F1-Score: {f1}')\n",
    "\n",
    "# Matriz de confusión\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(f'Confusion Matrix:\\n{cm}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T19:57:48.106995Z",
     "start_time": "2024-03-26T19:57:44.719237Z"
    }
   },
   "id": "12819d29e00e9922",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision by class: [0.01680672 0.02298851 0.03436426 0.00775194 0.0033557  0.03833866\n",
      " 0.         0.06666667 0.02162162 0.00746269 0.01570681 0.01438849\n",
      " 0.00404858 0.         0.01587302 0.         0.         0.01226994\n",
      " 0.         0.01       0.00666667 0.00740741 0.01612903 0.00819672\n",
      " 0.00813008 0.         0.02884615 0.00787402 0.         0.\n",
      " 0.01234568 0.         0.         0.         0.         0.03313253\n",
      " 0.0265252  0.01117318 0.01388889 0.         0.         0.03370787\n",
      " 0.         0.         0.01851852 0.01428571 0.02272727 0.\n",
      " 0.01470588 0.02512563 0.01621622 0.0173913  0.03546099 0.00645161\n",
      " 0.01041667 0.02339181 0.01587302 0.00564972 0.03389831 0.01851852\n",
      " 0.         0.02222222 0.01388889 0.         0.         0.03191489\n",
      " 0.         0.01273885 0.02083333 0.01183432 0.0075188  0.02222222\n",
      " 0.         0.         0.         0.00694444 0.02912621 0.\n",
      " 0.         0.         0.         0.         0.01470588 1.\n",
      " 0.00724638 0.         0.01       0.        ]\n",
      "F1-Score: 0.3631115346357012\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Calculando precisión con el manejo de división por cero\n",
    "precision = precision_score(y_true, y_pred, average=None, zero_division=1)\n",
    "print(f'Precision by class: {precision}')\n",
    "\n",
    "# Similarmente, para F1-Score, si es necesario\n",
    "f1 = f1_score(y_true, y_pred, average='macro', zero_division=1)\n",
    "print(f'F1-Score: {f1}')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T02:18:19.224781Z",
     "start_time": "2024-03-27T02:18:19.189775Z"
    }
   },
   "id": "ef4ac11c0a66117f",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision per class: [0.01680672268907563, 0.022988505747126436, 0.03436426116838488, 0.007751937984496124, 0.003355704697986577, 0.038338658146964855, 0.0, 0.06666666666666667, 0.021621621621621623, 0.007462686567164179, 0.015706806282722512, 0.014388489208633094, 0.004048582995951417, 0.0, 0.015873015873015872, 0.0, 0.0, 0.012269938650306749, 0.0, 0.01, 0.006666666666666667, 0.007407407407407408, 0.016129032258064516, 0.00819672131147541, 0.008130081300813009, 0.0, 0.028846153846153848, 0.007874015748031496, 0.0, 0.0, 0.012345679012345678, 0.0, 0.0, 0.0, 0.0, 0.03313253012048193, 0.026525198938992044, 0.0111731843575419, 0.013888888888888888, 0.0, 0.0, 0.033707865168539325, 0.0, 0.0, 0.018518518518518517, 0.014285714285714285, 0.022727272727272728, 0.0, 0.014705882352941176, 0.02512562814070352, 0.016216216216216217, 0.017391304347826087, 0.03546099290780142, 0.0064516129032258064, 0.010416666666666666, 0.023391812865497075, 0.015873015873015872, 0.005649717514124294, 0.03389830508474576, 0.018518518518518517, 0.0, 0.022222222222222223, 0.013888888888888888, 0.0, 0.0, 0.031914893617021274, 0.0, 0.012738853503184714, 0.020833333333333332, 0.011834319526627219, 0.007518796992481203, 0.022222222222222223, 0.0, 0.0, 0.0, 0.006944444444444444, 0.02912621359223301, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014705882352941176, 0, 0.007246376811594203, 0.0, 0.01, 0.0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "import numpy as np\n",
    "\n",
    "precision_per_class = []\n",
    "for i in range(len(cm)):\n",
    "    tp = cm[i, i]\n",
    "    fp = np.sum(cm[:, i]) - tp\n",
    "    if tp + fp == 0:\n",
    "        precision = 0  # O podrías elegir manejar esto de otra manera, como con un valor predeterminado.\n",
    "    else:\n",
    "        precision = tp / (tp + fp)\n",
    "    precision_per_class.append(precision)\n",
    "\n",
    "print(f'Precision per class: {precision_per_class}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T02:20:46.406833Z",
     "start_time": "2024-03-27T02:20:46.392301Z"
    }
   },
   "id": "7698cf590a036437",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "60a3ad1ccdc7e5f5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
